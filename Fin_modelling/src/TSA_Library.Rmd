---
title: "Frequently used functions"
author: "Avinash Kori (ED15B006)"
date: "9 November 2017"
output: pdf_document
---

Best method to simulate using auto arima models look at the methods :)
```{R gen model}
library(forecast)
  ar_order = {}
  ma_order = {}
  ar_arma_order = {}
  ma_arma_order = {}
  ar_aic = {}
  ma_aic = {}
  arma_aic = {}
  N = 6000
  for(i in 1:100){
  # Simulate 100 realizations for the given process
    
  wk = arima.sim(model = list(ar= c(0.2, 0, 0.1) ), n = N)
  
  # Fit best AR, MA and ARMA models for each of the realizations
  mod_ar = auto.arima(wk, max.p = 10 , max.q = 0 , ic = "aic") ;
  mod_ma = auto.arima(wk, max.p = 0 , max.q = 10 , ic = "aic") ;
  mod_arma = auto.arima(wk, max.p = 10 , max.q = 10 , start.p = 1, start.q = 1 , ic = "aic") ;
  
  # Store the best orders of AR, MA and ARMA for each of the noise realizations
  ar_order[i] = length(mod_ar$model$phi)
  ma_order[i] = length(mod_ma$model$theta)
  ar_arma_order[i] = length(mod_arma$model$phi)
  ma_arma_order[i] = length(mod_arma$model$theta)
  
  # Store minimum AIC values for each of the model structures for all the noise realizations
  
  ar_aic[i] = mod_ar$aic
  ma_aic[i] = mod_ma$aic
  arma_aic[i] = mod_arma$aic
  }
  
ar_ma_arma_aic = cbind(ar_aic, ma_aic, arma_aic)

# Indexing appropriate model based on minimum AIC for each realization
min_aic_struct = as.matrix(apply(ar_ma_arma_aic, 1, which.min))

# Frequency with which each of the model structures are identified across realizations

table(min_aic_struct)

# Determining the realization indices where the optimal model is AR
index1 = which(min_aic_struct %in% c(1))

# frequency with which true AR order is identified
freq_AR3 = length(which(ar_order[index1] %in% c(3)))
```


***

2) Harmonic trend removal and time series fitting
```{r harmonic model}
# data vk 
vk = arima.sim(model = list(ar= c(0.2, 0.1) ), n = 1000)

# Given time series
plot( vk, xlab = "Time", ylab = "Amplitude ", main = "Time series")

# Detecting the Periodicity from periodogram
x = seq( 0, 0.5-(1/length(vk)), by = (1/length(vk)));

y1 = abs(fft(vk))^2;# periodogram nr

N = length(vk)/2; 
y = y1[1:N];

plot(x, y, type = 'l', xlab = "Time", ylab = "Amplitude", main = "Periodogram" )
f0 = x[which.max(y)] # One dominant peak is observed. Others could be due to spectral leakage

# Periodicity modeling using harmonic regression
kvec = 0 : (length(vk)-1)

# All periodic signals can be modeled as linear combination of sin and cos
mod = lm(vk ~ I(sin(2*pi*f0*kvec)) + I(cos(2*pi*f0*kvec)))

lin_fit = as.ts(mod$coefficients[2]*sin(2*pi*f0*kvec) + mod$coefficients[3]*cos(2*pi*f0*kvec)+ mod$coefficients[1])

# overlapping plots
plot(y=lin_fit, x=time(vk), col='red', type='l', ylab="", main="True signal(blue); Harmonic Regression fit (red)", xlab="Time")
#lines(y=vk, x=time(vk), col='blue', xlab="Time")


#################################################################################################
#################################################################################################

# standard methods followed in building timeseries models
# Building timeseries models

vk_train = vk[1:700]
vk_test = vk[701:1000]

pacf(vk) # find appropriate AR model
mod_ar1 = arima (vk_train, order=c(5,0,0))

# After checking parameter significance, found out that AR(2) best 
mod_ar = arima (vk_train, order = c(2,0,0), include.mean = F)

# ACF plot of residuals
acf(mod_ar$resid)

# One step ahead predictions
n1 = length (mod_ar$model$phi)+1
vk_pred1 = filter(vk_test[1:299], mod_ar$model$phi, sides = 1)# sides is for causality
vk_pred = vk_pred1[2:299]
vk_true = vk_test[n1:300]


# overlapping prediction with true value plot one-step ahead predictions
plot (vk_true, col = 'blue',type = 'l', xlab = "Time", ylab = " " , main = " Prediction(red) vs True(blue)")
lines(vk_pred, col = 'red')

# write inferances after each steps
```


***

3) BLP statistics and model inferancing using different significan bands not needed untill asked for it
```{r blp stats}
vk = arima.sim(model = list(ar= c(0.2, 0.1) ), n = 1000)
modelsummary <- function(modarima, Lmax = 30) {
  # Print summary
  summary(modarima)
  # Extract residuals and plot them
  err_mod <- modarima$residuals
  N = length(err_mod)
  # layout(matrix(c(1,2,3),3,1,byrow=TRUE),heights=c(1,1,1))
  par(mfrow = c(3, 1), mai = c(0.6, 0.7, 0.2, 0.2))
  plot(scale(err_mod), type = "l", ylab = "Std. resid.", xlab = "")
  # Compute ACF of residuals
  acf_err <- acf(err_mod, lag.max = Lmax, main = "", plot = F)
  lowsig = -1.96/sqrt(N)
  upsig = 1.96/sqrt(N)
  plot(acf_err$lag * tsp(err_mod)[3], acf_err$acf, type = "h",
  main = "", ylab = "ACF of Resid", xlab = "", ylim = c(1.2 *
  lowsig, 1.2 * upsig))
  abline(h = upsig, col = "red", lty = "dashed")
  abline(h = lowsig, col = "red", lty = "dashed")
  abline(h = 0, col = "black")
  # Compute BLP statistic
  blpval <- NULL
  npar <- sum(modarima$arma[1:4])
  Lval <- (npar + 1):Lmax
  for (L in Lval) {
    blpval <- c(blpval, Box.test(modarima$residuals, lag = L,
    fitdf = npar)$p.value)
  }
  # Plot BLP statistic
  plot(1:Lmax, c(rep(NA, npar), blpval), ylab = "p-values",
  xlab = "Lag", ylim = c(0, 1))
  abline(h = 0.05, col = "red", lty = "dashed")
}

modsarima <- stats::arima(vk, order = c(3, 0, 3), seasonal = list(order = c(2,0, 2)))

# Examine the diagnostics
modelsummary(modsarima)
```
Higher p value more acceptable 


***


4) imp functions
```{R functions}
NMSE <- function(pred, true, N, coeff){
  cv_sum_mean_sqerr <- sum((true-pred)^2)/(N-length(coeff))# N-order for unbiasedness
  wk_test_mean_sumsqrr <- sum((true-mean(true))^2)
  return(cv_sum_mean_sqerr/wk_test_mean_sumsqrr)
}

periodogram <- function(vk){
  y1 = abs(fft(vk))^2;# periodogram nr
  N = length(vk)/2; 
  y = y1[1:N];
  x = seq( 0, 0.5-(1/length(vk)), by = (1/length(vk)));
  plot(x, y, type = 'l', xlab = "Time", ylab = "Amplitude", main = "Periodogram" )
  f0 = x[which.max(y)]
  return(f0)
}

boxcox <- function(y, lambda){
  return((y^{lambda}-1)/lambda)
}

unit_root <- function(data){
  adf.test(data)
  # less p value unit root test qualified
}

```

5) SARIMA model......
```{r sarima}
vk <- rnorm(1000)
# vk detrended sequence first ar, second ma...
modsarima <- stats::arima(vk, order = c(3, 0, 3), seasonal = list(order = c(2,0, 2)))
```

6) Advanced peridogram filters
```{r periodogram filters}
daniell_filter<- function(data, windowsize){
  s <- (windowsize-1)/2
  per <- spec.pgram(data, spans = c(s,s), taper = 0, log = 'no')
  # repeate across realizations
  return(per)
}
# OR use SDF from sapa package
# method 
ek <- rnorm(1000)
library(sapa)
# direct normal periodogram
ek.directper <- SDF(ek, method = 'direct')
# daniell filter lag window
ek.daniell_filter <- SDF(ek, method = 'lag window', taper. = taper(type = 'parzen', n.sample = 1000))
# WOSA welch perodogram
ek.wosa <- SDF(ek, method = 'wosa', blocksize = 128)

# parametric method
ek.psd <- spec.ar(ek, plot = F)

ek1 <- rnorm(1000)
ek2 <- rnorm(1000)
x <- cbind(ek1,ek2)
ek.wosa_cross <- SDF(x, method = 'wosa', blocksize = 128)[,2]# if doubt look at atributes...
```



***

hannan algorithm: 

+ first fit AR of higher order
+ consider residuals of AR as ek
+ fit lm regression of required model p,q
+ take all q*ek and substract from vk repeat from step 1 again for certain threshold

```{r hannan algorithm}
hannan_algo <- function(vk, p,q){# p AR coefficients, q MA coefficients
  ek <- ar.yw(vk, aic=T)
  # max p,q == 2, 2
  regression <- lm(vk[p:length(vk)] ~ I(vk[p-1:length(vk)-1]) + I(vk[p-2: length(vk)-2]) + I(ek[q:length(ek)])+ I(ek[q-1:length(ek)-1])+I(ek[q-2:length(ek)-2]))
  return(regression)
}
```

